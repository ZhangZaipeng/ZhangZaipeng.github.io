一、查询，修改，删除，创建数据库：
    1.创建数据库
        CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name
          [COMMENT database_comment]
          [LOCATION hdfs_path]
          [WITH DBPROPERTIES (property_name=property_value, ...)];
        例：
        创建数据库hive
        create database hive;
        对应于HDFS的目录是：/user/hive/warehouse/hive.db

        如果hive数据库不存在就创建
        create database IF NOT EXISTS hive;

        在指定的路径下创建数据库
        create database hive2 LOCATION '/my/directory';

        创建数据库，并为数据库添加描述信息
        create database hive3 COMMENT 'it is my database'
        WITH DBPROPERTIES('creator'='zhangsan','date'='2016-10-10');
    2.查询数据库
        show databases;  查看数据库
        show databases like 'hive*';  查询以hive开头的数据库
        desc database hive2;  查看数据库hive2结构
        desc database extended hive2;  查看数据库hive2的详细描述信息
        use default;   切换数据库
    3.修改数据库
        ALTER (DATABASE|SCHEMA) database_name SET DBPROPERTIES (property_name=property_value, ...);
        eg: ALTER DATABASE hive3 SET DBPROPERTIES('edited-by'='lisi');
    4.删除数据库
        DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];
        eg:
            删除数据库hive3
            DROP DATABASE IF EXISTS hive3;（此命令不能删除含有表的数据库）
            强制删除数据库
            DROP DATABASE IF EXISTS hive2 CASCADE;（此命令可以删除含有表的数据库）
二、Hive的基本数据类型,
    TINYINT、SMALLINT、INT、BIGINT、FLOAT、DOUBLE、DECIMAL、
    BINARY、BOOLEAN、STRING、CHAR、VARCHAR、DETA、TIMESTAMP

    Hive分隔符
    行与行之间的分隔符
    记录字段之间的分隔符
    数组和结构体之间的分隔符
    键值对之间的分隔符

    分隔符：
    zhangsan,20,male
    lisi,29,female
    zhangsan$$$20$$$male
    lisi$$$29$$$female
三、查询，修改，删除，创建表
    1.创建表
        CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name    -- (Note: TEMPORARY available in Hive 0.14.0 and later)
          [(col_name data_type [COMMENT col_comment], ...)]
          [COMMENT table_comment]
          [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]
          [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]
          [SKEWED BY (col_name, col_name, ...)                  -- (Note: Available in Hive 0.10.0 and later)]
             ON ((col_value, col_value, ...), (col_value, col_value, ...), ...)
             [STORED AS DIRECTORIES]
          [
           [ROW FORMAT row_format]
           [STORED AS file_format]
             | STORED BY 'storage.handler.class.name' [WITH SERDEPROPERTIES (...)]  -- (Note: Available in Hive 0.6.0 and later)
          ]
          [LOCATION hdfs_path]
          [TBLPROPERTIES (property_name=property_value, ...)]   -- (Note: Available in Hive 0.6.0 and later)
          [AS select_statement];   -- (Note: Available in Hive 0.5.0 and later; not supported for external tables)

        CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name
          LIKE existing_table_or_view_name
          [LOCATION hdfs_path];

        data_type
          : primitive_type
          | array_type
          | map_type
          | struct_type
          | union_type  -- (Note: Available in Hive 0.7.0 and later)

        primitive_type
          : TINYINT
          | SMALLINT
          | INT
          | BIGINT
          | BOOLEAN
          | FLOAT
          | DOUBLE
          | STRING
          | BINARY      -- (Note: Available in Hive 0.8.0 and later)
          | TIMESTAMP   -- (Note: Available in Hive 0.8.0 and later)
          | DECIMAL     -- (Note: Available in Hive 0.11.0 and later)
          | DECIMAL(precision, scale)  -- (Note: Available in Hive 0.13.0 and later)
          | DATE        -- (Note: Available in Hive 0.12.0 and later)
          | VARCHAR     -- (Note: Available in Hive 0.12.0 and later)
          | CHAR        -- (Note: Available in Hive 0.13.0 and later)

        array_type
          : ARRAY < data_type >
          map_type
          : MAP < primitive_type, data_type >

        struct_type
          : STRUCT < col_name : data_type [COMMENT col_comment], ...>

        union_type
           : UNIONTYPE < data_type, data_type, ... >  -- (Note: Available in Hive 0.7.0 and later)

        row_format
          : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]
                [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]
                [NULL DEFINED AS char]   -- (Note: Available in Hive 0.13 and later)
          | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]

        file_format:
          : SEQUENCEFILE
          | TEXTFILE    -- (Default, depending on hive.default.fileformat configuration)
          | RCFILE      -- (Note: Available in Hive 0.6.0 and later)
          | ORC         -- (Note: Available in Hive 0.11.0 and later)
          | PARQUET     -- (Note: Available in Hive 0.13.0 and later)
          | AVRO        -- (Note: Available in Hive 0.14.0 and later)
          | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname
    创建emp表
        create table emp(
        empno int, ename string, job string, mgr int,
        hiredate string, sal double, comm double, deptno int
        )ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';

        将本地文件的内容导入到emp表中
        load data local inpath '/home/hadoop/data/emp.txt' overwrite into table emp;

        create table emp2 like emp;  只拷贝表结果，不拷贝表数据
        create table emp3 as select * from emp;  不仅拷贝表结果，而且拷贝表数据

    2.查看表
        show tables;  查看当前数据库的所有表
        show tables 'emp*';  查看当前数据库中以emp开头的表
        desc emp;  查看表emp的结构
        desc extended emp;  查看表emp的详细描述信息
        desc formatted emp;  查看表emp的详细描述信息（详细信息以特定的格式展现）
        select * from emp;  查看表emp中的数据信息

    3.修改表
        ALTER TABLE table_name RENAME TO new_table_name;
        ALTER TABLE emp2 RENAME TO emp2_bak;  修改emp2的表名为emp2_bak

    4.删除表
        DROP TABLE [IF EXISTS] table_name [PURGE];
        DROP TABLE IF EXISTS emp2_bak;  删除表emp2_bak
四、内部表和外部表的区别
    内部表：managed_table
    	在删除时，HDFS数据被删除，MySQL元数据也被删除
    外部表：EXTERNAL
    create EXTERNAL table emp_external(
    empno int, ename string, job string, mgr int,
    hiredate string, sal double, comm double, deptno int
    )ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
    location '/hive_external/emp/';
    	在删除时，HDFS数据不被删除，MySQL元数据被删除
五、表数据加载，数据导出
    1.表数据加载
        LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE
        tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]

        LOCAL：从本地文件加载数据到hive表；否则就是从HDFS加载数据到Hive表；
        OVERWRITE：是否覆盖表里的数据；

        加载本地文件的内容到表emp中（覆盖掉表中原有的数据）
        load data local inpath '/home/hadoop/data/emp.txt' overwrite into table emp;

        在hdfs上创建多层目录
        hadoop fs -mkdir -p /data/hive

        将本地文件上传至hdfs上
        hadoop fs -put /home/hadoop/data/emp.txt /data/hive

        将hdfs上的数据加载到emp表中（如果emp表原来有数据，则覆盖掉emp表中原来的数据）
        load data inpath '/data/hive/emp.txt' overwrite into table emp;

        //只加载源表的3个字段到目标表
        create table emp1 as select empno,ename, job from emp;

    2.数据导出
        INSERT OVERWRITE [LOCAL] DIRECTORY directory1
          [ROW FORMAT row_format] [STORED AS file_format] (Note: Only available starting with Hive 0.11.0)
          SELECT ... FROM ...

        将emp中的数据导出到本地系统的指定目录下
        INSERT OVERWRITE LOCAL DIRECTORY '/home/hadoop/data/tmp'
        ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' select * from emp;

        用hdfs命令将数据库表emp中的数据导出到本地文件系统的当前目录下
        hadoop fs -get /user/hive/warehouse/emp

六、Hive分区表(静态分区：单级分区、多级分区，动态分区：...)
    1.静态分区创建
    创建单级分区表order_partition：
    create table order_partition(
    order_number string,
    event_time string
    )
    PARTITIONED BY(event_month string)
    ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';

    加载本地数据到到分区表
    load data local inpath '/home/hadoop/data/order.txt' overwrite into table order_partition partition(event_month='2014-05');

    在hdfs上创建分区目录
    hadoop fs -mkdir -p /user/hive/warehouse/order_partition/event_month=2014-06
    将本地数据上传到hdfs上创建好的分区目录
    hadoop fs -put order.txt /user/hive/warehouse/order_partition/event_month=2014-06

    刷新表order_partition
    Msck repair table order_partition;
七、复杂数据类型（Array、struct、map）
    创建数组表hive_array
    create table hive_array(
    name string,
    work_locations array<string>
    )
    ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
    COLLECTION ITEMS TERMINATED BY ',';

    加载本地数据到数组表
    load data local inpath '/home/hadoop/data/hive_array.txt'
    overwrite into table hive_array ;

    查询数组的大小
    select name,size(work_locations) from hive_array;

    创建map表hive_map
    create table hive_map(
    name string,
    scores map<string,int>
    )
    ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
    COLLECTION ITEMS TERMINATED BY ','
    MAP KEYS TERMINATED BY ':';

    加载本地数据到hive_map
    load data local inpath '/home/hadoop/data/hive_map.txt'
    overwrite into table hive_map ;
    查询学生的英语成绩
    select name,scores[english] from hive_map;

    创建结构体表hive_struct
    create table hive_struct(
    ip string,
    userinfo struct<name:string,age:int>
    )
    ROW FORMAT DELIMITED FIELDS TERMINATED BY '#'
    COLLECTION ITEMS TERMINATED BY ':';

    加载本地数据到表hive_struct
    load data local inpath '/home/hadoop/data/hive_struct.txt'
    overwrite into table hive_struct ;